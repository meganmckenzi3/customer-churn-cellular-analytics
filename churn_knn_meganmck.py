# -*- coding: utf-8 -*-
"""churn.knn.MeganMcK

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13vQ-59bFqxhJMrzecC31po51pf3mwMsv

Churn data from a cellphone company can predict customer churn by assesing multiple features. In the .csv file there are 15 features the user can choose from when we apply the K Nearest Neighbor Algorithm. The goal of this assignment is apply KNN to new data and see how well the model is able to classify the churn data as TRUE or FALSE.

KNN can make highly accurate predictions as a supervised machine learning algorithm.
Before applying KNN to the dataset, I ran several iterations of the model using different features.
"""

#1. Import libraries necessary
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
plt.style.use('fivethirtyeight')
# %matplotlib inline

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import GridSearchCV

#2)Load the data set into Google Colab or development environment
dataset= pd.read_csv('Churn.csv')

#3) Familiarize yourself with the data by looking at it's shape properties
dataset.shape

#The first five rows of data.
dataset.head(5)

#Examining the actual data itself
dataset.describe

#We could assume what data is categorical vs. numerical but we can also do it using code.
categorical = dataset.select_dtypes(include=[object])
print("Categorical Columns:",categorical.shape[1])

numerical = dataset.select_dtypes(exclude=[object])
print("Numerical Columns:",numerical.shape[1])

#This will us if there any missing values in our data we should clean up in our preparation stages.
dataset.isnull().any().any()

#4) Divide the data into features and labels.
#Features are the columns we will be using as input in data.
#Label will be the churn column- the output we are trying to predict.
#We will start by creating two arrays which hold the X (features) and y (labels)
feature_columns = ['Total day minutes', 'Customer service calls', 'Total day charge','Total eve charge']
X = dataset[feature_columns].values
y = dataset['Churn'].values

#5) Label Encoding
#This process will turn strings (labels) into a numerical form the machine can read, strings are not acceptable.
# Labels before encoding, True/False
print(y)
# from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)
# Labels after encoding 0/1
print(y)

#6) Splitting dataset into training set and test set
#This process is used to avoid over-fitting the data. This features allows users to split data into train and test.
#A 80/20 split applied to train and test data means 80% of the records will become training data and 20% of the records will be test data.
# from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42, stratify=y)

X_train.shape

#7) Feature scaling
#In the pre-processing of data feature scaling is standard practice for standardizing features into a certain range.
#Standard_Scaler will scale to unit variance, meaning it will divide all units by the standard deviation
scaler = StandardScaler()
scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

#8) Data visualization
#This may help us see how features are related, and gain insights on large amounts of data.
#The Andrew Curves: Analyzing multivariate data using curves.
from pandas.plotting import andrews_curves
plt.figure(figsize=(15,10))
andrews_curves(dataset, "Churn")
plt.title('Andrews Curves Plot', fontsize=20, fontweight='bold')
plt.legend(loc=1, prop={'size': 15}, frameon=True,shadow=True, facecolor="white", edgecolor="black")
plt.show()

"""How do we interpret the Andrew Curves Plot?
In this graph the individual datapoints are visualized as curves.The shape of the curve compared to other curves if where our information comes from, not necessarly the shape of just one curve. The overlapping of the lines for False in some areas of the plot suggest that there is not distinct differences in between those datapoints.
"""

#Boxplots
plt.figure()
dataset.boxplot(by="Churn", figsize=(15, 10))
plt.show()

"""Boxplots are commonly used to tell us how our data is spreadout. In this case we are comparing how the data is spread for each feature and whether the churn was true or false. It can also show if the data is skewed or has any outliers."""

#Correlation Heatmap
plt.figure(figsize=(20,12))
#draws heatmap with input as the correlation matrix calculted by(data.corr())
sns.heatmap(dataset.corr().abs(), annot=True, cmap='RdYlGn')
plt.title('Correlation Heatmap')
plt.show()

"""Correlation heatmaps can be used to how variables relate to each other, 1.0 indicates a perfect positive correlation. While one value (x) increases so does the other value (y). It can determine the strength of relationships between variables."""

#9) Using KNN for classification
#The first step will be fitting the classifier to the Training set.
#We will use a K value of 9 because previous test iterations have shown it to be the ideal number neighbors.
# Fitting clasifier to the Training set
# Loading libraries
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, accuracy_score
from sklearn.model_selection import cross_val_score

# Instantiate learning model (k = 3)
classifier = KNeighborsClassifier(n_neighbors=9)

# Fitting the model
classifier.fit(X_train, y_train)

# Predicting the Test set results
y_pred = classifier.predict(X_test)

#10) Evaluating predictions with a confusion matrix
#This will show the error or confusion in the model with each 114 were correcly predicted with 1 error, and 12 were predicted with 7 errors between True and False.
confusion_matrix(y_test,y_pred)

#11) Using a Classification Report
#This shows the precision (successful identfication), recall, F1-score (weighted average of recall) and overall accuray of the model.
#Remember 0 and 1 actually represent True and False
print(classification_report(y_test,y_pred))

#Calculating Model Accuray
#This function will allow us to see how accurate our model is.
accuracy = accuracy_score(y_test, y_pred)*100
print('Accuracy of our model is equal ' + str(round(accuracy, 2)) + ' %.')

#12) For my method of cross-validation for parameter tuning, I have chosen to use plt.

#This method will use a for loop to go through a list of k values and determine which produced the best cross validation score.
# creating list of K for KNN
k_list = list(range(1,50,2))
# creating list of cv scores
cv_scores = []

# perform 10-fold cross validation
for k in k_list:
    knn = KNeighborsClassifier(n_neighbors=k)
    scores = cross_val_score(knn, X_train, y_train, cv=10, scoring='accuracy')
    cv_scores.append(scores.mean())

# changing to misclassification error
MSE = [1 - x for x in cv_scores]

plt.figure()
plt.figure(figsize=(15,10))
plt.title('The optimal number of neighbors', fontsize=20, fontweight='bold')
plt.xlabel('Number of Neighbors K', fontsize=15)
plt.ylabel('Misclassification Error', fontsize=15)
sns.set_style("whitegrid")
plt.plot(k_list, MSE)

plt.show()

# finding best k
best_k = k_list[MSE.index(min(MSE))]
print("The optimal number of neighbors is %d." % best_k)